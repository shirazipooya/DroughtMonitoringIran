{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "هدف من این است که نتایج جدول زیر 15 درصد بهتر شوند.\n",
    "خروجی مد نظر:\n",
    "1- جدول پیش‌بینی‌شده از Report جدید\n",
    "2- Confusion Matrix بهبود‌یافته رو به شکل Heatmap تصویری هم بکش\n",
    "\n",
    "Overall Accuracy: 0.6979\n",
    "Macro-F1 Score: 0.3946\n",
    "Cohen's Kappa: 0.3476\n",
    "\n",
    "Classification Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "          ED       1.00      0.50      0.67        10\n",
    "          EW       0.00      0.00      0.00         3\n",
    "          MD       0.21      0.08      0.12        49\n",
    "          MW       0.49      0.31      0.38        54\n",
    "          NN       0.75      0.94      0.84       309\n",
    "          SD       0.52      0.34      0.42        32\n",
    "          VW       0.50      0.26      0.34        23\n",
    "\n",
    "    accuracy                           0.70       480\n",
    "   macro avg       0.50      0.35      0.39       480\n",
    "weighted avg       0.64      0.70      0.65       480\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import sqlite3\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import plotly.express as px\n",
    "import skill_metrics as sm\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as scs\n",
    "import seaborn as sns\n",
    "\n",
    "import spei\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_DIR = 'results/Stations'\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "sys.path.append('/home/pooya/w/DroughtMonitoringIran/')\n",
    "DATABASE_PATH = \"./database/database.db\"\n",
    "conn = sqlite3.connect(DATABASE_PATH)\n",
    "data_raw = pd.read_sql(sql='SELECT * FROM data', con=conn)\n",
    "data_raw['Date'] = pd.to_datetime(data_raw[\"Date\"], format=\"%Y-%m\")\n",
    "conn.close()\n",
    "\n",
    "# Filter Data\n",
    "# - Cluster 1 - Sari\n",
    "# - Cluster 2 - Alasht\n",
    "# - Cluster 3 - Ramsar\n",
    "selected_stations = [\"Sari\", \"Alasht\", \"Ramsar\"]\n",
    "start_date = \"2006-09\"\n",
    "end_date = \"2023-10\"\n",
    "\n",
    "selected_features = [\n",
    "    'Station_ID',\n",
    "    'Station_Name',\n",
    "    'Date',\n",
    "    'NDVI',\n",
    "    'EVI',\n",
    "    'VCI',\n",
    "    'TCI',\n",
    "    'VHI',\n",
    "    'PCI_GPM',\n",
    "    'CI_GPM',\n",
    "]\n",
    "\n",
    "for di in ['SPEI', 'SPI']:\n",
    "    for scale in [1, 3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "        selected_features.append(f'{di}_{scale}')\n",
    "        selected_features.append(f'GPM_{di}_{scale}')\n",
    "\n",
    "data = data_raw[selected_features]\\\n",
    "    .query(\"Station_Name in @selected_stations and Date >= @start_date and Date < @end_date\")\n",
    "\n",
    "\n",
    "for di in ['SPEI', 'SPI']:\n",
    "    for scale in [1, 3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "        data[f'{di}_{scale}_Class'] = pd.cut(data[f'{di}_{scale}'], bins=[-10, -2, -1.5, -1, 1, 1.5, 2, 10], labels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW'])\n",
    "        data[f'{di}_{scale}_Class'] = data[f'{di}_{scale}_Class'].astype('category')\n",
    "\n",
    "        data[f'GPM_{di}_{scale}_Class'] = pd.cut(data[f'GPM_{di}_{scale}'], bins=[-10, -2, -1.5, -1, 1, 1.5, 2, 10], labels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW'])\n",
    "        data[f'GPM_{di}_{scale}_Class'] = data[f'GPM_{di}_{scale}_Class'].astype('category')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station: Ramsar, Index: SPEI, Scale: 1\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPEI, Scale: 3\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPEI, Scale: 6\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPEI, Scale: 9\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPEI, Scale: 12\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPEI, Scale: 15\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPEI, Scale: 18\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPEI, Scale: 21\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPEI, Scale: 24\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPI, Scale: 1\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPI, Scale: 3\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPI, Scale: 6\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPI, Scale: 9\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPI, Scale: 12\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPI, Scale: 15\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPI, Scale: 18\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPI, Scale: 21\n",
      "\n",
      "\n",
      "\n",
      "Station: Ramsar, Index: SPI, Scale: 24\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPEI, Scale: 1\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPEI, Scale: 3\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPEI, Scale: 6\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPEI, Scale: 9\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPEI, Scale: 12\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPEI, Scale: 15\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPEI, Scale: 18\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPEI, Scale: 21\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPEI, Scale: 24\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPI, Scale: 1\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPI, Scale: 3\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPI, Scale: 6\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPI, Scale: 9\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPI, Scale: 12\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPI, Scale: 15\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPI, Scale: 18\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPI, Scale: 21\n",
      "\n",
      "\n",
      "\n",
      "Station: Sari, Index: SPI, Scale: 24\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPEI, Scale: 1\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPEI, Scale: 3\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPEI, Scale: 6\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPEI, Scale: 9\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPEI, Scale: 12\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPEI, Scale: 15\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPEI, Scale: 18\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPEI, Scale: 21\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPEI, Scale: 24\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPI, Scale: 1\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPI, Scale: 3\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPI, Scale: 6\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPI, Scale: 9\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPI, Scale: 12\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPI, Scale: 15\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPI, Scale: 18\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPI, Scale: 21\n",
      "\n",
      "\n",
      "\n",
      "Station: Alasht, Index: SPI, Scale: 24\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame(columns=[\n",
    "    'Station', 'Index', 'Scale', 'Accuracy',\n",
    "    'Precision', 'Recall', 'F1-score'\n",
    "])\n",
    "\n",
    "for st in data['Station_Name'].unique():\n",
    "    df_st = data.query(\"Station_Name == @st\")\n",
    "    for di in ['SPEI', 'SPI']:\n",
    "        for scale in [1, 3, 6, 9, 12, 15, 18, 21, 24]:\n",
    "            \n",
    "            df = df_st[[\n",
    "                'Station_ID',\n",
    "                'Station_Name',\n",
    "                'Date', \n",
    "                f'{di}_{scale}',\n",
    "                f'GPM_{di}_{scale}',\n",
    "                f'{di}_{scale}_Class', \n",
    "                f'GPM_{di}_{scale}_Class'\n",
    "                \n",
    "            ]].dropna()\n",
    "            \n",
    "            df.set_index('Date', inplace=True)\n",
    "            \n",
    "            print(f\"Station: {st}, Index: {di}, Scale: {scale}\")\n",
    "            report_dict = classification_report(\n",
    "                y_true=df[f'{di}_{scale}_Class'],\n",
    "                y_pred=df[f'GPM_{di}_{scale}_Class'],\n",
    "                labels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW'],\n",
    "                output_dict=True\n",
    "            )\n",
    "            \n",
    "            results_df.loc[len(results_df)] = [\n",
    "                st, di, scale,\n",
    "                report_dict['accuracy'],\n",
    "                report_dict['weighted avg']['precision'],\n",
    "                report_dict['weighted avg']['recall'],\n",
    "                report_dict['weighted avg']['f1-score']\n",
    "            ]\n",
    "            \n",
    "            cm = confusion_matrix(\n",
    "                y_true=df[f'{di}_{scale}_Class'], \n",
    "                y_pred=df[f'GPM_{di}_{scale}_Class'],\n",
    "                labels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW']\n",
    "            )\n",
    "            plt.figure(figsize=(10, 8))\n",
    "            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW'], yticklabels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW'])\n",
    "            plt.title(f'{st} - {di} {scale}-month')\n",
    "            plt.ylabel('Actual')\n",
    "            plt.xlabel('Predicted')\n",
    "            fig_path = os.path.join(RESULTS_DIR, f'{st}-{di}-{scale} - Confusion Matrix.png')\n",
    "            plt.savefig(fig_path, bbox_inches='tight')\n",
    "            plt.close()            \n",
    "            \n",
    "            # Plot time series for station and GPM index\n",
    "            f, ax = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "            spei.plot.si(df[f'{di}_{scale}'], ax=ax[0], cmap=\"vik_r\")\n",
    "            spei.plot.si(df[f'GPM_{di}_{scale}'], ax=ax[1], cmap=\"vik_r\")\n",
    "            ax[0].set_xlim(pd.to_datetime([start_date, end_date]))\n",
    "            ax[0].set_title(f'{st} - {di} {scale}-month', fontsize=16)\n",
    "            [x.grid() for x in ax]\n",
    "            [ax[i].set_ylabel(n, fontsize=14) for i, n in enumerate([f'{di}{scale} (Station)', f'{di}{scale} (GPM)'])]\n",
    "            plt.tight_layout()\n",
    "            fig_path = os.path.join(RESULTS_DIR, f'{st}-{di}-{scale} - Timeseries.png')\n",
    "            f.savefig(fig_path, bbox_inches='tight')\n",
    "            plt.close(f)\n",
    "\n",
    "results_df.to_csv(os.path.join(RESULTS_DIR, 'classification_results.csv'), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.model_evaluator import ModelEvaluator\n",
    "\n",
    "for st in selected_stations:\n",
    "    print(f\"\\nMetrics for Station ID: {st}\")\n",
    "    ModelEvaluator(df.query('Station_Name == @st'), f'{di}_{scale}', f'GPM_{di}_{scale}').display_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "for st in selected_stations:\n",
    "    station_data = df.query('Station_Name == @st')\n",
    "    fig = px.scatter(station_data, x=f'{di}_{scale}', y=f'GPM_{di}_{scale}', title=st)\n",
    "    max_limit = max(station_data[f'{di}_{scale}'].max(), station_data[f'GPM_{di}_{scale}'].max())\n",
    "    min_limit = max(station_data[f'{di}_{scale}'].min(), station_data[f'GPM_{di}_{scale}'].min())\n",
    "    fig.update_layout(xaxis=dict(range=[min_limit, max_limit]), yaxis=dict(range=[min_limit, max_limit]))\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "    fig.update_xaxes(constrain='domain')\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "x=f'{di}_{scale}'\n",
    "y=f'GPM_{di}_{scale}'\n",
    "\n",
    "for st in selected_stations:\n",
    "    station_data = data.query(\"Station_Name == @st\")[['Date', x, y]].dropna()\n",
    "\n",
    "    fig = px.scatter(\n",
    "        station_data,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        labels={\n",
    "            x: f\"{st}<br>{di}{scale} (Station)\",\n",
    "            y: f'{di}{scale} (GPM)'\n",
    "        },\n",
    "        opacity=0.7,\n",
    "        color_discrete_sequence=[\"black\"],  # make points black\n",
    "    )\n",
    "\n",
    "    # Make scatter markers bigger\n",
    "    fig.update_traces(marker=dict(size=8, color=\"black\"))\n",
    "\n",
    "    # Equal axis limits\n",
    "    max_limit = max(station_data[x].max(),\n",
    "                    station_data[y].max()) + 0.5\n",
    "    min_limit = min(station_data[x].min(),\n",
    "                    station_data[y].min()) - 0.5\n",
    "    \n",
    "    # Equal ticks\n",
    "    tick_vals = np.arange(min_limit, max_limit, 1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        xaxis=dict(range=[min_limit, max_limit]),\n",
    "        yaxis=dict(range=[min_limit, max_limit]),\n",
    "        width=600,\n",
    "        height=600,\n",
    "        title=None,\n",
    "        margin=dict(l=20, r=20, t=20, b=20),\n",
    "    )\n",
    "    fig.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n",
    "\n",
    "    # Add 1:1 line (hidden from legend)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=[min_limit, max_limit],\n",
    "        y=[min_limit, max_limit],\n",
    "        mode=\"lines\",\n",
    "        line=dict(color=\"red\", dash=\"dash\"),\n",
    "        showlegend=False\n",
    "    ))\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = df.query('Station_Name == \"Bandar-e-anzali\"')\n",
    "df_plot.set_index('Date', inplace=True)\n",
    "\n",
    "f, ax = plt.subplots(7, 1, figsize=(8, 12), sharex=True)\n",
    "spei.plot.si(df_plot['NDVI'], ax=ax[0], cmap=\"vik_r\")\n",
    "spei.plot.si(df_plot['EVI'], ax=ax[1], cmap=\"roma\")\n",
    "spei.plot.si(df_plot['PCI_GPM'], ax=ax[2], cmap=\"seismic_r\")\n",
    "spei.plot.si(df_plot['VCI'], ax=ax[3], cmap=\"roma\")\n",
    "spei.plot.si(df_plot['TCI'], ax=ax[4], cmap=\"vik_r\")\n",
    "spei.plot.si(df_plot['VHI'], ax=ax[5], cmap=\"seismic_r\")\n",
    "spei.plot.si(df_plot['CI_GPM'], ax=ax[6], cmap=\"roma\")\n",
    "ax[0].set_xlim(pd.to_datetime([\"2014\", \"2024\"]))\n",
    "ax[0].set_ylim(-0.2, 1)\n",
    "ax[1].set_ylim(-0.2, 1)\n",
    "ax[2].set_ylim(0, 1)\n",
    "ax[3].set_ylim(0, 1)\n",
    "ax[4].set_ylim(0, 1)\n",
    "ax[5].set_ylim(0, 1)\n",
    "ax[6].set_ylim(0, 1)\n",
    "[x.grid() for x in ax]\n",
    "[ax[i].set_ylabel(n, fontsize=14) for i, n in enumerate(['NDVI', 'EVI', 'PCI', 'VCI', 'TCI', 'VHI', 'CI'])];"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "droughtmonitoringiran (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
