{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-17 14:14:13.054377: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-17 14:14:13.062164: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-01-17 14:14:13.083356: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1737110653.117209   32921 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1737110653.127132   32921 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import sqlite3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import skill_metrics as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "import scipy. stats as scs\n",
    "import xgboost as xgb\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier, AdaBoostRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('/home/pooya/w/DroughtMonitoringIran/')\n",
    "\n",
    "DATABASE_PATH = \"./database/database.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(DATABASE_PATH)\n",
    "\n",
    "data = pd.read_sql(sql='SELECT * FROM data', con=conn)\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Station_ID',\n",
       " 'Station_Name',\n",
       " 'Province',\n",
       " 'Station_Latitude',\n",
       " 'Station_Longitude',\n",
       " 'Station_Elevation',\n",
       " 'Date',\n",
       " 'Temperature_Maximum',\n",
       " 'Temperature_Minimum',\n",
       " 'Temperature',\n",
       " 'Precipitation',\n",
       " 'PET_Hargreaves',\n",
       " 'SPI_1',\n",
       " 'SPEI_1',\n",
       " 'SPI_3',\n",
       " 'SPEI_3',\n",
       " 'SPI_6',\n",
       " 'SPEI_6',\n",
       " 'SPI_9',\n",
       " 'SPEI_9',\n",
       " 'SPI_12',\n",
       " 'SPEI_12',\n",
       " 'SPI_15',\n",
       " 'SPEI_15',\n",
       " 'SPI_18',\n",
       " 'SPEI_18',\n",
       " 'SPI_21',\n",
       " 'SPEI_21',\n",
       " 'SPI_24',\n",
       " 'SPEI_24',\n",
       " 'ERA5_Precipitation',\n",
       " 'GPM_Precipitation',\n",
       " 'TRMM_Precipitation',\n",
       " 'TERRACLIMATE_Precipitation',\n",
       " 'PERSIANNCDR_Precipitation',\n",
       " 'PET_MOD16A2GF',\n",
       " 'NDVI_MOD13A3',\n",
       " 'LSTDay_MOD21C3',\n",
       " 'LSTNight_MYD21C3',\n",
       " 'EVI_MYD13A3',\n",
       " 'LSTNight_MOD21C3',\n",
       " 'NDVI_MYD13A3',\n",
       " 'LSTDay_MYD21C3',\n",
       " 'EVI_MOD13A3',\n",
       " 'NDVI',\n",
       " 'EVI',\n",
       " 'LSTDay',\n",
       " 'LSTNight',\n",
       " 'LST',\n",
       " 'PCI_ERA5',\n",
       " 'PCI_GPM',\n",
       " 'PCI_TRMM',\n",
       " 'PCI_TerraClimate',\n",
       " 'PCI_PERSIANNCDR',\n",
       " 'VCI',\n",
       " 'TCI',\n",
       " 'VHI',\n",
       " 'CI_GPM',\n",
       " 'CI_ERA5',\n",
       " 'CI_TRMM',\n",
       " 'CI_TerraClimate',\n",
       " 'CI_PERSIANNCDR',\n",
       " 'ERA5_SPI_1',\n",
       " 'ERA5_SPEI_1',\n",
       " 'GPM_SPI_1',\n",
       " 'GPM_SPEI_1',\n",
       " 'TRMM_SPI_1',\n",
       " 'TRMM_SPEI_1',\n",
       " 'TERRACLIMATE_SPI_1',\n",
       " 'TERRACLIMATE_SPEI_1',\n",
       " 'PERSIANNCDR_SPI_1',\n",
       " 'PERSIANNCDR_SPEI_1',\n",
       " 'ERA5_SPI_3',\n",
       " 'ERA5_SPEI_3',\n",
       " 'GPM_SPI_3',\n",
       " 'GPM_SPEI_3',\n",
       " 'TRMM_SPI_3',\n",
       " 'TRMM_SPEI_3',\n",
       " 'TERRACLIMATE_SPI_3',\n",
       " 'TERRACLIMATE_SPEI_3',\n",
       " 'PERSIANNCDR_SPI_3',\n",
       " 'PERSIANNCDR_SPEI_3',\n",
       " 'ERA5_SPI_6',\n",
       " 'ERA5_SPEI_6',\n",
       " 'GPM_SPI_6',\n",
       " 'GPM_SPEI_6',\n",
       " 'TRMM_SPI_6',\n",
       " 'TRMM_SPEI_6',\n",
       " 'TERRACLIMATE_SPI_6',\n",
       " 'TERRACLIMATE_SPEI_6',\n",
       " 'PERSIANNCDR_SPI_6',\n",
       " 'PERSIANNCDR_SPEI_6',\n",
       " 'ERA5_SPI_9',\n",
       " 'ERA5_SPEI_9',\n",
       " 'GPM_SPI_9',\n",
       " 'GPM_SPEI_9',\n",
       " 'TRMM_SPI_9',\n",
       " 'TRMM_SPEI_9',\n",
       " 'TERRACLIMATE_SPI_9',\n",
       " 'TERRACLIMATE_SPEI_9',\n",
       " 'PERSIANNCDR_SPI_9',\n",
       " 'PERSIANNCDR_SPEI_9',\n",
       " 'ERA5_SPI_12',\n",
       " 'ERA5_SPEI_12',\n",
       " 'GPM_SPI_12',\n",
       " 'GPM_SPEI_12',\n",
       " 'TRMM_SPI_12',\n",
       " 'TRMM_SPEI_12',\n",
       " 'TERRACLIMATE_SPI_12',\n",
       " 'TERRACLIMATE_SPEI_12',\n",
       " 'PERSIANNCDR_SPI_12',\n",
       " 'PERSIANNCDR_SPEI_12',\n",
       " 'ERA5_SPI_15',\n",
       " 'ERA5_SPEI_15',\n",
       " 'GPM_SPI_15',\n",
       " 'GPM_SPEI_15',\n",
       " 'TRMM_SPI_15',\n",
       " 'TRMM_SPEI_15',\n",
       " 'TERRACLIMATE_SPI_15',\n",
       " 'TERRACLIMATE_SPEI_15',\n",
       " 'PERSIANNCDR_SPI_15',\n",
       " 'PERSIANNCDR_SPEI_15',\n",
       " 'ERA5_SPI_18',\n",
       " 'ERA5_SPEI_18',\n",
       " 'GPM_SPI_18',\n",
       " 'GPM_SPEI_18',\n",
       " 'TRMM_SPI_18',\n",
       " 'TRMM_SPEI_18',\n",
       " 'TERRACLIMATE_SPI_18',\n",
       " 'TERRACLIMATE_SPEI_18',\n",
       " 'PERSIANNCDR_SPI_18',\n",
       " 'PERSIANNCDR_SPEI_18',\n",
       " 'ERA5_SPI_21',\n",
       " 'ERA5_SPEI_21',\n",
       " 'GPM_SPI_21',\n",
       " 'GPM_SPEI_21',\n",
       " 'TRMM_SPI_21',\n",
       " 'TRMM_SPEI_21',\n",
       " 'TERRACLIMATE_SPI_21',\n",
       " 'TERRACLIMATE_SPEI_21',\n",
       " 'PERSIANNCDR_SPI_21',\n",
       " 'PERSIANNCDR_SPEI_21',\n",
       " 'ERA5_SPI_24',\n",
       " 'ERA5_SPEI_24',\n",
       " 'GPM_SPI_24',\n",
       " 'GPM_SPEI_24',\n",
       " 'TRMM_SPI_24',\n",
       " 'TRMM_SPEI_24',\n",
       " 'TERRACLIMATE_SPI_24',\n",
       " 'TERRACLIMATE_SPEI_24',\n",
       " 'PERSIANNCDR_SPI_24',\n",
       " 'PERSIANNCDR_SPEI_24']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "di = 'SPI'\n",
    "di_scale = 1\n",
    "\n",
    "selected_columns = [\n",
    "    'Station_ID',\n",
    "    'Station_Latitude', 'Station_Longitude', 'Station_Elevation',\n",
    "    'Date', # 'Year', 'Month',\n",
    "    f'{di}_{di_scale}',\n",
    "    'GPM_Precipitation',\n",
    "    'PET_MOD16A2GF',\n",
    "    'NDVI', 'EVI',\n",
    "    'LSTDay', 'LSTNight', 'LST',\n",
    "    'PCI_GPM', 'VCI', 'TCI', 'VHI', 'CI_GPM',\n",
    "    f'GPM_{di}_{di_scale}'\n",
    " ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4992 entries, 0 to 4991\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count  Dtype   \n",
      "---  ------             --------------  -----   \n",
      " 0   Station_ID         4992 non-null   category\n",
      " 1   Station_Latitude   4992 non-null   float64 \n",
      " 2   Station_Longitude  4992 non-null   float64 \n",
      " 3   Station_Elevation  4992 non-null   float64 \n",
      " 4   SPI_1              4992 non-null   float64 \n",
      " 5   GPM_Precipitation  4992 non-null   float64 \n",
      " 6   PET_MOD16A2GF      4992 non-null   float64 \n",
      " 7   NDVI               4992 non-null   float64 \n",
      " 8   EVI                4992 non-null   float64 \n",
      " 9   LSTDay             4992 non-null   float64 \n",
      " 10  LSTNight           4992 non-null   float64 \n",
      " 11  LST                4992 non-null   float64 \n",
      " 12  PCI_GPM            4992 non-null   float64 \n",
      " 13  VCI                4992 non-null   float64 \n",
      " 14  TCI                4992 non-null   float64 \n",
      " 15  VHI                4992 non-null   float64 \n",
      " 16  CI_GPM             4992 non-null   float64 \n",
      " 17  GPM_SPI_1          4992 non-null   float64 \n",
      " 18  Year               4992 non-null   int32   \n",
      " 19  Month              4992 non-null   int32   \n",
      " 20  SPI_1_Class        4992 non-null   category\n",
      " 21  GPM_SPI_1_Class    4992 non-null   category\n",
      "dtypes: category(3), float64(17), int32(2)\n",
      "memory usage: 718.2 KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Station_ID</th>\n",
       "      <th>Station_Latitude</th>\n",
       "      <th>Station_Longitude</th>\n",
       "      <th>Station_Elevation</th>\n",
       "      <th>SPI_1</th>\n",
       "      <th>GPM_Precipitation</th>\n",
       "      <th>PET_MOD16A2GF</th>\n",
       "      <th>NDVI</th>\n",
       "      <th>EVI</th>\n",
       "      <th>LSTDay</th>\n",
       "      <th>...</th>\n",
       "      <th>PCI_GPM</th>\n",
       "      <th>VCI</th>\n",
       "      <th>TCI</th>\n",
       "      <th>VHI</th>\n",
       "      <th>CI_GPM</th>\n",
       "      <th>GPM_SPI_1</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>SPI_1_Class</th>\n",
       "      <th>GPM_SPI_1_Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40709</td>\n",
       "      <td>38.365</td>\n",
       "      <td>48.855</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>0.577</td>\n",
       "      <td>115.920</td>\n",
       "      <td>125.725</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.308</td>\n",
       "      <td>27.62</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.416</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.308</td>\n",
       "      <td>2006</td>\n",
       "      <td>9</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40709</td>\n",
       "      <td>38.365</td>\n",
       "      <td>48.855</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>0.182</td>\n",
       "      <td>164.424</td>\n",
       "      <td>80.775</td>\n",
       "      <td>0.599</td>\n",
       "      <td>0.318</td>\n",
       "      <td>24.01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.492</td>\n",
       "      <td>0.832</td>\n",
       "      <td>0.393</td>\n",
       "      <td>0.613</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.658</td>\n",
       "      <td>2006</td>\n",
       "      <td>10</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40709</td>\n",
       "      <td>38.365</td>\n",
       "      <td>48.855</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>-0.405</td>\n",
       "      <td>101.520</td>\n",
       "      <td>44.000</td>\n",
       "      <td>0.554</td>\n",
       "      <td>0.286</td>\n",
       "      <td>17.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.411</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.377</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.480</td>\n",
       "      <td>-0.171</td>\n",
       "      <td>2006</td>\n",
       "      <td>11</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40709</td>\n",
       "      <td>38.365</td>\n",
       "      <td>48.855</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>-0.303</td>\n",
       "      <td>77.376</td>\n",
       "      <td>35.025</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0.236</td>\n",
       "      <td>10.15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.633</td>\n",
       "      <td>-0.206</td>\n",
       "      <td>2006</td>\n",
       "      <td>12</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40709</td>\n",
       "      <td>38.365</td>\n",
       "      <td>48.855</td>\n",
       "      <td>-21.1</td>\n",
       "      <td>-1.251</td>\n",
       "      <td>26.040</td>\n",
       "      <td>60.400</td>\n",
       "      <td>0.418</td>\n",
       "      <td>0.195</td>\n",
       "      <td>9.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.233</td>\n",
       "      <td>-1.997</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>MD</td>\n",
       "      <td>SD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>99361</td>\n",
       "      <td>36.071</td>\n",
       "      <td>52.843</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>-0.839</td>\n",
       "      <td>20.088</td>\n",
       "      <td>239.275</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.219</td>\n",
       "      <td>34.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.222</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.406</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.763</td>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>99361</td>\n",
       "      <td>36.071</td>\n",
       "      <td>52.843</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>0.694</td>\n",
       "      <td>35.280</td>\n",
       "      <td>176.650</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.175</td>\n",
       "      <td>26.76</td>\n",
       "      <td>...</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.593</td>\n",
       "      <td>-0.142</td>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>99361</td>\n",
       "      <td>36.071</td>\n",
       "      <td>52.843</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>64.728</td>\n",
       "      <td>123.012</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.185</td>\n",
       "      <td>22.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.445</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.673</td>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>99361</td>\n",
       "      <td>36.071</td>\n",
       "      <td>52.843</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>0.574</td>\n",
       "      <td>46.080</td>\n",
       "      <td>98.800</td>\n",
       "      <td>0.395</td>\n",
       "      <td>0.187</td>\n",
       "      <td>17.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.331</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.353</td>\n",
       "      <td>0.346</td>\n",
       "      <td>-0.580</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>99361</td>\n",
       "      <td>36.071</td>\n",
       "      <td>52.843</td>\n",
       "      <td>1805.0</td>\n",
       "      <td>-0.178</td>\n",
       "      <td>23.064</td>\n",
       "      <td>57.588</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.183</td>\n",
       "      <td>11.68</td>\n",
       "      <td>...</td>\n",
       "      <td>0.080</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.379</td>\n",
       "      <td>-1.158</td>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>NN</td>\n",
       "      <td>MD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4992 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Station_ID  Station_Latitude  Station_Longitude  Station_Elevation  \\\n",
       "0         40709            38.365             48.855              -21.1   \n",
       "1         40709            38.365             48.855              -21.1   \n",
       "2         40709            38.365             48.855              -21.1   \n",
       "3         40709            38.365             48.855              -21.1   \n",
       "4         40709            38.365             48.855              -21.1   \n",
       "...         ...               ...                ...                ...   \n",
       "4987      99361            36.071             52.843             1805.0   \n",
       "4988      99361            36.071             52.843             1805.0   \n",
       "4989      99361            36.071             52.843             1805.0   \n",
       "4990      99361            36.071             52.843             1805.0   \n",
       "4991      99361            36.071             52.843             1805.0   \n",
       "\n",
       "      SPI_1  GPM_Precipitation  PET_MOD16A2GF   NDVI    EVI  LSTDay  ...  \\\n",
       "0     0.577            115.920        125.725  0.510  0.308   27.62  ...   \n",
       "1     0.182            164.424         80.775  0.599  0.318   24.01  ...   \n",
       "2    -0.405            101.520         44.000  0.554  0.286   17.30  ...   \n",
       "3    -0.303             77.376         35.025  0.462  0.236   10.15  ...   \n",
       "4    -1.251             26.040         60.400  0.418  0.195    9.84  ...   \n",
       "...     ...                ...            ...    ...    ...     ...  ...   \n",
       "4987 -0.839             20.088        239.275  0.420  0.219   34.26  ...   \n",
       "4988  0.694             35.280        176.650  0.380  0.175   26.76  ...   \n",
       "4989  0.585             64.728        123.012  0.394  0.185   22.45  ...   \n",
       "4990  0.574             46.080         98.800  0.395  0.187   17.29  ...   \n",
       "4991 -0.178             23.064         57.588  0.453  0.183   11.68  ...   \n",
       "\n",
       "      PCI_GPM    VCI    TCI    VHI  CI_GPM  GPM_SPI_1  Year  Month  \\\n",
       "0       0.456  0.271  0.562  0.416   0.430      0.308  2006      9   \n",
       "1       0.492  0.832  0.393  0.613   0.573      0.658  2006     10   \n",
       "2       0.411  0.651  0.377  0.514   0.480     -0.171  2006     11   \n",
       "3       0.522  0.460  0.916  0.688   0.633     -0.206  2006     12   \n",
       "4       0.000  0.486  0.213  0.350   0.233     -1.997  2007      1   \n",
       "...       ...    ...    ...    ...     ...        ...   ...    ...   \n",
       "4987    0.222  0.537  0.274  0.406   0.345      0.763  2023      8   \n",
       "4988    0.455  0.375  0.948  0.662   0.593     -0.142  2023      9   \n",
       "4989    0.522  0.445  0.699  0.572   0.555      0.673  2023     10   \n",
       "4990    0.331  0.706  0.000  0.353   0.346     -0.580  2023     11   \n",
       "4991    0.080  1.000  0.056  0.528   0.379     -1.158  2023     12   \n",
       "\n",
       "      SPI_1_Class  GPM_SPI_1_Class  \n",
       "0              NN               NN  \n",
       "1              NN               NN  \n",
       "2              NN               NN  \n",
       "3              NN               NN  \n",
       "4              MD               SD  \n",
       "...           ...              ...  \n",
       "4987           NN               NN  \n",
       "4988           NN               NN  \n",
       "4989           NN               NN  \n",
       "4990           NN               NN  \n",
       "4991           NN               MD  \n",
       "\n",
       "[4992 rows x 22 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.filter(items=selected_columns)\n",
    "df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m')\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Station_ID'] = df['Station_ID'].astype('category')\n",
    "df.drop(columns=['Date'], inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.sort_values(by=['Station_ID', 'Year', 'Month'], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df[f'{di}_{di_scale}_Class'] = pd.cut(df[f'{di}_{di_scale}'], bins=[-10, -2, -1.5, -1, 1, 1.5, 2, 10], labels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW'])\n",
    "df[f'GPM_{di}_{di_scale}_Class'] = pd.cut(df[f'GPM_{di}_{di_scale}'], bins=[-10, -2, -1.5, -1, 1, 1.5, 2, 10], labels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW'])\n",
    "print(df.info())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(\n",
    "    columns=[\n",
    "        'Station_ID',\n",
    "        f'{di}_{di_scale}',\n",
    "        f'{di}_{di_scale}_Class',\n",
    "        f'GPM_{di}_{di_scale}',\n",
    "        f'GPM_{di}_{di_scale}_Class'\n",
    "    ]\n",
    ")\n",
    "\n",
    "y = df[f'{di}_{di_scale}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Scale the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Apply Scaling to the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Feature selection using Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance:\n",
      "PCI_GPM: 0.3973645607549658\n",
      "PET_MOD16A2GF: 0.0664966355082667\n",
      "GPM_Precipitation: 0.05373104417039949\n",
      "LSTDay: 0.053149753891575904\n",
      "TCI: 0.0479037920724396\n",
      "Year: 0.0438243029061867\n",
      "LSTNight: 0.03952892537620254\n",
      "LST: 0.03944846770432121\n",
      "NDVI: 0.03679412625626445\n",
      "CI_GPM: 0.036440212478689074\n",
      "VCI: 0.032327357674628555\n",
      "VHI: 0.03127930693279001\n",
      "EVI: 0.031260815366401726\n",
      "Station_Longitude: 0.024699963477739954\n",
      "Station_Elevation: 0.024398964691129902\n",
      "Station_Latitude: 0.021156187224782706\n",
      "Month: 0.020195583513215723\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(random_state=1)\n",
    "\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "\n",
    "importances = rf.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "print(\"Feature Importance:\")\n",
    "for f in range(X_train.shape[1]):\n",
    "    print(f\"{X_train.columns[indices[f]]}: {importances[indices[f]]}\")\n",
    "\n",
    "sfm = SelectFromModel(\n",
    "    estimator=rf,\n",
    "    threshold=\"mean\",\n",
    "    max_features=5\n",
    ")\n",
    "\n",
    "sfm.fit(X_train_scaled, y_train)\n",
    "\n",
    "X_train_selected = sfm.transform(X_train_scaled)\n",
    "\n",
    "X_test_selected = sfm.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Hyperparameter tuning for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Hyperparameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 400],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "rf_grid_search = GridSearchCV(\n",
    "    estimator=RandomForestRegressor(random_state=1),\n",
    "    param_grid=rf_param_grid, \n",
    "    cv=5, \n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "rf_grid_search.fit(X_train_selected, y_train)\n",
    "\n",
    "print(\"Best Random Forest Hyperparameters:\", rf_grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest RMSE: 1.2510871883478212\n",
      "Random Forest R²: 0.2658055236939467\n"
     ]
    }
   ],
   "source": [
    "rf_best_model = rf_grid_search.best_estimator_\n",
    "rf_preds = rf_best_model.predict(X_test_selected)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_preds))\n",
    "rf_r2 = r2_score(y_test, rf_preds)\n",
    "\n",
    "print(f\"Random Forest RMSE: {rf_rmse}\")\n",
    "print(f\"Random Forest R²: {rf_r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-by-Step Code for AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.values)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled,\n",
    "    y.values,\n",
    "    test_size=0.2,\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "base_estimator = DecisionTreeRegressor()\n",
    "\n",
    "adaboost_model = AdaBoostRegressor(\n",
    "    estimator=base_estimator,\n",
    "    n_estimators=50, \n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "adaboost_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = adaboost_model.feature_importances_\n",
    "\n",
    "# Create a DataFrame to display feature importances\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': ['Station_Latitude', 'Station_Longitude', 'Station_Elevation', 'GPM_Precipitation', 'PET_MOD16A2GF', 'NDVI', 'EVI', 'LSTDay', 'LSTNight', 'LST', 'PCI_GPM', 'VCI', 'TCI', 'VHI', 'CI_GPM', 'Year', 'Month'],\n",
    "    'Importance': feature_importances\n",
    "})\n",
    "\n",
    "# Sort features by importance\n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Display the sorted feature importances\n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the Top Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select top N features (e.g., top 5)\n",
    "top_n = 5\n",
    "top_features = feature_importance_df['Feature'].head(top_n).values\n",
    "\n",
    "# Filter the original dataset based on the top features\n",
    "X_top = df[top_features].values\n",
    "\n",
    "# Scale the selected features\n",
    "X_top_scaled = scaler.fit_transform(X_top)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_top, X_test_top, y_train, y_test = train_test_split(X_top_scaled, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Retrain AdaBoost with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train AdaBoost with the selected top features\n",
    "adaboost_model_top = AdaBoostRegressor(estimator=base_estimator, n_estimators=50, random_state=42)\n",
    "adaboost_model_top.fit(X_train_top, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Predict on the test data using the new model\n",
    "y_pred_top = adaboost_model_top.predict(X_test_top)\n",
    "\n",
    "# Calculate RMSE and R²\n",
    "rmse_top = np.sqrt(mean_squared_error(y_test, y_pred_top))\n",
    "r2_top = r2_score(y_test, y_pred_top)\n",
    "\n",
    "print(f\"RMSE with Top Features: {rmse_top}\")\n",
    "print(f\"R² with Top Features: {r2_top}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = X_scaled.reshape((X_scaled.shape[0], 1, X_scaled.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = list(selected_features)  # From RFE, or you can choose based on RF feature importance\n",
    "\n",
    "# Subset the original data to only include the selected features\n",
    "X_selected = X[final_features]\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_class, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Selected Features for Final Model:\", final_features)\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation (Optional: You can evaluate using RMSE, R^2, etc.)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# Print the metrics\n",
    "print(f'Precision: {precision:.4f}')\n",
    "print(f'Recall: {recall:.4f}')\n",
    "print(f'F1-Score: {f1:.4f}')\n",
    "\n",
    "# 9. **Plot Precision, Recall, and F1-Score**\n",
    "metrics = [precision, recall, f1]\n",
    "metric_names = ['Precision', 'Recall', 'F1-Score']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=metric_names, y=metrics, palette='viridis')\n",
    "plt.ylabel('Score')\n",
    "plt.ylim(0, 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW'])\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW'], yticklabels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.cut(y, bins=[-10, -2, -1.5, -1, 1, 1.5, 2, 10], labels=['ED', 'SD', 'MD', 'NN', 'MW', 'VW', 'EW'])\n",
    "\n",
    "print(f\"Model R^2: {rf.score(X_test, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = precision_score(y_test, y_pred, average='weighted')\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
